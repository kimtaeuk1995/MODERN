{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import requests\n",
    "import urllib.request\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4 import Comment\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n"
   ]
  },
  {
   "source": [
    "# Sofa"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'sofa'\n",
    "\n",
    "product_dir = os.path.join('images', data_dir)\n",
    "counter = 0\n",
    "if not os.path.exists(product_dir):\n",
    "    os.makedirs(product_dir)\n",
    "\n",
    "path = \"/usr/local/bin/chromedriver\"\n",
    "driver = webdriver.Chrome(path)\n",
    "\n",
    "url = 'https://www.allmodern.com/furniture/cat/sofas-sectionals-c527685.html#sbprodgrid'\n",
    "driver.get(url)\n",
    "\n",
    "full_df_sofa = pd.DataFrame(columns=['id', 'website_link', 'image_link', 'prices', 'category'])\n",
    "counter = 0 \n",
    "\n",
    "for i in range(1, 11):\n",
    "    time.sleep(2)\n",
    "    #driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "    if  5 > i >= 2:\n",
    "        i = i+1\n",
    "        \n",
    "    elif 9 > i >= 5:\n",
    "        i = 4\n",
    "    \n",
    "    elif i == 9:\n",
    "        i = 5\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    img = soup.find('div', {'class': 'Category-productWrap is-loaded'})\n",
    "\n",
    "    image_link = []\n",
    "    prices = []\n",
    "    website_link = []\n",
    "    id = []\n",
    "\n",
    "    for image in img.findAll('img', attrs={'srcset':True}):\n",
    "        image = image.attrs['srcset'][1+image.attrs['srcset'].find(','):image.attrs['srcset'].find('.310w')-4]\n",
    "        if ('data:image') in image:\n",
    "                pass\n",
    "        else:\n",
    "            urllib.request.urlretrieve(image, product_dir+'/'+data_dir+str(counter)+'.jpg')\n",
    "            image_link.append(image)\n",
    "            id.append(data_dir+str(counter))\n",
    "            counter += 1\n",
    "    \n",
    "    for website in img.findAll('a', {'href':True}):\n",
    "        website = website['href']\n",
    "        website_link.append(website)\n",
    "\n",
    "\n",
    "    for price in img.findAll('div',{'class':'ProductCard-pricing'}):\n",
    "        price = price.find('span', {'class':'ProductCard-price'}).text\n",
    "        prices.append(price)\n",
    "\n",
    "    data = pd.DataFrame(dict(zip(['id', 'website_link', 'image_link', 'prices'],[id, website_link, image_link, prices])))\n",
    "    data['category'] = data_dir\n",
    "    \n",
    "    full_df_sofa = full_df_sofa.append(data)\n",
    "\n",
    "    if i == 10:\n",
    "        break\n",
    "    \n",
    "    element = driver.find_element_by_xpath('//*[@id=\"bd\"]/div[2]/div[2]/nav/a[{}]'.format(i))\n",
    "    element.click()\n",
    "\n",
    "    time.sleep(10)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "source": [
    "# Chairs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_chair = pd.DataFrame(columns=['website_link', 'image_link', 'prices', 'category'])\n",
    "\n",
    "data_dir = 'chairs'\n",
    "\n",
    "product_dir = os.path.join('images', data_dir)\n",
    "counter = 0\n",
    "if not os.path.exists(product_dir):\n",
    "    os.makedirs(product_dir)\n",
    "\n",
    "path = \"/usr/local/bin/chromedriver\"\n",
    "driver = webdriver.Chrome(path)\n",
    "\n",
    "url = 'https://www.allmodern.com/furniture/sb0/accent-chairs-c365818.html'\n",
    "driver.get(url)\n",
    "\n",
    "counter = 0 \n",
    "\n",
    "for i in range(1, 11):\n",
    "    time.sleep(2)\n",
    "    #driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "    if  5 > i >= 2:\n",
    "        i = i+1\n",
    "        \n",
    "    elif 9 > i >= 5:\n",
    "        i = 4\n",
    "    \n",
    "    elif i == 9:\n",
    "        i = 5\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    img = soup.find('div', {'data-hb-id': 'pl-grid-v2'})\n",
    "\n",
    "    image_link = []\n",
    "    prices = []\n",
    "    website_link = []\n",
    "\n",
    "    for image in img.findAll('img', attrs={'srcset':True}):\n",
    "        image = image.attrs['srcset'][1+image.attrs['srcset'].find(','):image.attrs['srcset'].find('.310w')-4]\n",
    "        if ('data:image') in image:\n",
    "                pass\n",
    "        else:\n",
    "            urllib.request.urlretrieve(image, product_dir+'/'+data_dir+str(counter)+'.jpg')\n",
    "            image_link.append(image)\n",
    "            counter += 1\n",
    "    \n",
    "    for website in img.findAll('a', {'href':True}):\n",
    "        website = website['href']\n",
    "        website_link.append(website)\n",
    "\n",
    "    if i == 1:\n",
    "        for price in img.findAll('div',{'class':'ProductCard-pricing'}):\n",
    "            price = price.find('span', {'class':'ProductCard-price'}).text\n",
    "            prices.append(price)    \n",
    "    else:\n",
    "        for price in img.findAll('div',{'class':'BrowseMinimizedPriceBlock'}):\n",
    "            price = price.find('span', {'class':'BrowseMinimizedPriceBlock-price'}).text\n",
    "            prices.append(price)\n",
    "\n",
    "\n",
    "    data = pd.DataFrame(dict(zip(['website_link', 'image_link', 'prices'],[website_link, image_link, prices])))\n",
    "    data['category'] = data_dir\n",
    "    full_df_chair = full_df_chair.append(data)\n",
    "\n",
    "    if i == 10:\n",
    "        break\n",
    "\n",
    "    element = driver.find_element_by_xpath('//*[@id=\"sbprodgrid\"]/div[3]/div/nav/a[{}]'.format(i))\n",
    "    element.click()\n",
    "\n",
    "    time.sleep(10)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "source": [
    "# Console Tables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_consoletable = pd.DataFrame(columns=['website_link', 'image_link', 'prices', 'category'])\n",
    "\n",
    "data_dir = 'console table'\n",
    "\n",
    "product_dir = os.path.join('images', data_dir)\n",
    "counter = 0\n",
    "if not os.path.exists(product_dir):\n",
    "    os.makedirs(product_dir)\n",
    "\n",
    "path = \"/usr/local/bin/chromedriver\"\n",
    "driver = webdriver.Chrome(path)\n",
    "\n",
    "url = 'https://www.allmodern.com/furniture/sb0/console-tables-c413349.html'\n",
    "driver.get(url)\n",
    "\n",
    "counter = 0 \n",
    "\n",
    "for i in range(1, 5):\n",
    "    time.sleep(2)\n",
    "    #driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "    if  5 > i >= 2:\n",
    "        i = i+1\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    img = soup.find('div', {'data-hb-id': 'pl-grid-v2'})\n",
    "\n",
    "    image_link = []\n",
    "    prices = []\n",
    "    website_link = []\n",
    "\n",
    "    for image in img.findAll('img', attrs={'srcset':True}):\n",
    "        image = image.attrs['srcset'][1+image.attrs['srcset'].find(','):image.attrs['srcset'].find('.310w')-4]\n",
    "        if ('data:image') in image:\n",
    "                pass\n",
    "        else:\n",
    "            urllib.request.urlretrieve(image, product_dir+'/'+data_dir+str(counter)+'.jpg')\n",
    "            image_link.append(image)\n",
    "            counter += 1\n",
    "    \n",
    "    for website in img.findAll('a', {'href':True}):\n",
    "        website = website['href']\n",
    "        website_link.append(website)\n",
    "\n",
    "    if i == 1:\n",
    "        for price in img.findAll('div',{'class':'ProductCard-pricing'}):\n",
    "            price = price.find('span', {'class':'ProductCard-price'}).text\n",
    "            prices.append(price)    \n",
    "    else:\n",
    "        for price in img.findAll('div',{'class':'BrowseMinimizedPriceBlock'}):\n",
    "            price = price.find('span', {'class':'BrowseMinimizedPriceBlock-price'}).text\n",
    "            prices.append(price)\n",
    "\n",
    "\n",
    "    data = pd.DataFrame(dict(zip(['website_link', 'image_link', 'prices'],[website_link, image_link, prices])))\n",
    "    data['category'] = data_dir\n",
    "    full_df_consoletable = full_df_consoletable.append(data)\n",
    "    \n",
    "    if i == 5:\n",
    "        break\n",
    "    element = driver.find_element_by_xpath('//*[@id=\"sbprodgrid\"]/div[3]/div/nav/a[{}]'.format(i))\n",
    "    element.click()\n",
    "\n",
    "    time.sleep(10)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "source": [
    "# TV Stands"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_tvstand = pd.DataFrame(columns=['website_link', 'image_link', 'prices', 'category'])\n",
    "\n",
    "data_dir = 'tv stand'\n",
    "\n",
    "product_dir = os.path.join('images', data_dir)\n",
    "counter = 0\n",
    "if not os.path.exists(product_dir):\n",
    "    os.makedirs(product_dir)\n",
    "\n",
    "path = \"/usr/local/bin/chromedriver\"\n",
    "driver = webdriver.Chrome(path)\n",
    "\n",
    "url = 'https://www.allmodern.com/furniture/sb0/tv-stands-c445006.html'\n",
    "driver.get(url)\n",
    "\n",
    "counter = 0 \n",
    "\n",
    "for i in range(1, 5):\n",
    "    time.sleep(2)\n",
    "    #driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "    if  5 > i >= 2:\n",
    "        i = i+1\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    img = soup.find('div', {'data-hb-id': 'pl-grid-v2'})\n",
    "\n",
    "    image_link = []\n",
    "    prices = []\n",
    "    website_link = []\n",
    "\n",
    "    for image in img.findAll('img', attrs={'srcset':True}):\n",
    "        image = image.attrs['srcset'][1+image.attrs['srcset'].find(','):image.attrs['srcset'].find('.310w')-4]\n",
    "        if ('data:image') in image:\n",
    "                pass\n",
    "        else:\n",
    "            urllib.request.urlretrieve(image, product_dir+'/'+data_dir+str(counter)+'.jpg')\n",
    "            image_link.append(image)\n",
    "            counter += 1\n",
    "    \n",
    "    for website in img.findAll('a', {'href':True}):\n",
    "        website = website['href']\n",
    "        website_link.append(website)\n",
    "\n",
    "    if i == 1:\n",
    "        for price in img.findAll('div',{'class':'ProductCard-pricing'}):\n",
    "            price = price.find('span', {'class':'ProductCard-price'}).text\n",
    "            prices.append(price)    \n",
    "    else:\n",
    "        for price in img.findAll('div',{'class':'BrowseMinimizedPriceBlock'}):\n",
    "            price = price.find('span', {'class':'BrowseMinimizedPriceBlock-price'}).text\n",
    "            prices.append(price)\n",
    "\n",
    "\n",
    "    data = pd.DataFrame(dict(zip(['website_link', 'image_link', 'prices'],[website_link, image_link, prices])))\n",
    "    data['category'] = data_dir\n",
    "    full_df_tvstand = full_df_tvstand.append(data)\n",
    "    \n",
    "    if i == 5:\n",
    "        break\n",
    "    element = driver.find_element_by_xpath('//*[@id=\"sbprodgrid\"]/div[3]/div/nav/a[{}]'.format(i))\n",
    "    element.click()\n",
    "\n",
    "    time.sleep(10)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "source": [
    "# Coffee Tables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_coffeetable = pd.DataFrame(columns=['website_link', 'image_link', 'prices', 'category'])\n",
    "\n",
    "data_dir = 'coffee tables'\n",
    "\n",
    "product_dir = os.path.join('images', data_dir)\n",
    "counter = 0\n",
    "if not os.path.exists(product_dir):\n",
    "    os.makedirs(product_dir)\n",
    "\n",
    "path = \"/usr/local/bin/chromedriver\"\n",
    "driver = webdriver.Chrome(path)\n",
    "\n",
    "url = 'https://www.allmodern.com/furniture/sb0/coffee-tables-c413347.html'\n",
    "driver.get(url)\n",
    "\n",
    "counter = 0 \n",
    "\n",
    "for i in range(1, 10):\n",
    "    time.sleep(2)\n",
    "    #driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "    if  5 > i >= 2:\n",
    "        i = i+1\n",
    "        \n",
    "    elif 8 > i >= 5:\n",
    "        i = 4\n",
    "    \n",
    "    elif i == 8:\n",
    "        i = 5\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    img = soup.find('div', {'data-hb-id': 'pl-grid-v2'})\n",
    "\n",
    "    image_link = []\n",
    "    prices = []\n",
    "    website_link = []\n",
    "\n",
    "    for image in img.findAll('img', attrs={'srcset':True}):\n",
    "        image = image.attrs['srcset'][1+image.attrs['srcset'].find(','):image.attrs['srcset'].find('.310w')-4]\n",
    "        if ('data:image') in image:\n",
    "                pass\n",
    "        else:\n",
    "            urllib.request.urlretrieve(image, product_dir+'/'+data_dir+str(counter)+'.jpg')\n",
    "            image_link.append(image)\n",
    "            counter += 1\n",
    "    \n",
    "    for website in img.findAll('a', {'href':True}):\n",
    "        website = website['href']\n",
    "        website_link.append(website)\n",
    "\n",
    "    if i == 1:\n",
    "        for price in img.findAll('div',{'class':'ProductCard-pricing'}):\n",
    "            price = price.find('span', {'class':'ProductCard-price'}).text\n",
    "            prices.append(price)    \n",
    "    else:\n",
    "        for price in img.findAll('div',{'class':'BrowseMinimizedPriceBlock'}):\n",
    "            price = price.find('span', {'class':'BrowseMinimizedPriceBlock-price'}).text\n",
    "            prices.append(price)\n",
    "\n",
    "\n",
    "    data = pd.DataFrame(dict(zip(['website_link', 'image_link', 'prices'],[website_link, image_link, prices])))\n",
    "    data['category'] = data_dir\n",
    "    full_df_coffeetable = full_df_coffeetable.append(data)\n",
    "\n",
    "    if i == 9:\n",
    "        break\n",
    "    element = driver.find_element_by_xpath('//*[@id=\"sbprodgrid\"]/div[3]/div/nav/a[{}]'.format(i))\n",
    "    element.click()\n",
    "    \n",
    "    time.sleep(10)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "source": [
    "# End Tables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_endtable = pd.DataFrame(columns=['website_link', 'image_link', 'prices', 'category'])\n",
    "\n",
    "data_dir = 'end tables'\n",
    "\n",
    "product_dir = os.path.join('images', data_dir)\n",
    "counter = 0\n",
    "if not os.path.exists(product_dir):\n",
    "    os.makedirs(product_dir)\n",
    "\n",
    "path = \"/usr/local/bin/chromedriver\"\n",
    "driver = webdriver.Chrome(path)\n",
    "\n",
    "url = 'https://www.allmodern.com/furniture/sb0/end-side-tables-c413348.html'\n",
    "driver.get(url)\n",
    "\n",
    "counter = 0 \n",
    "\n",
    "for i in range(1, 10):\n",
    "    time.sleep(2)\n",
    "    #driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "    if  5 > i >= 2:\n",
    "        i = i+1\n",
    "        \n",
    "    elif 8 > i >= 5:\n",
    "        i = 4\n",
    "\n",
    "    elif i == 8:\n",
    "        i = 5\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    img = soup.find('div', {'data-hb-id': 'pl-grid-v2'})\n",
    "\n",
    "    image_link = []\n",
    "    prices = []\n",
    "    website_link = []\n",
    "\n",
    "    for image in img.findAll('img', attrs={'srcset':True}):\n",
    "        image = image.attrs['srcset'][1+image.attrs['srcset'].find(','):image.attrs['srcset'].find('.310w')-4]\n",
    "        if ('data:image') in image:\n",
    "                pass\n",
    "        else:\n",
    "            urllib.request.urlretrieve(image, product_dir+'/'+data_dir+str(counter)+'.jpg')\n",
    "            image_link.append(image)\n",
    "            counter += 1\n",
    "    \n",
    "    for website in img.findAll('a', {'href':True}):\n",
    "        website = website['href']\n",
    "        website_link.append(website)\n",
    "\n",
    "    if i == 1:\n",
    "        for price in img.findAll('div',{'class':'ProductCard-pricing'}):\n",
    "            price = price.find('span', {'class':'ProductCard-price'}).text\n",
    "            prices.append(price)    \n",
    "    else:\n",
    "        for price in img.findAll('div',{'class':'BrowseMinimizedPriceBlock'}):\n",
    "            price = price.find('span', {'class':'BrowseMinimizedPriceBlock-price'}).text\n",
    "            prices.append(price)\n",
    "\n",
    "\n",
    "    data = pd.DataFrame(dict(zip(['website_link', 'image_link', 'prices'],[website_link, image_link, prices])))\n",
    "    data['category'] = data_dir\n",
    "    full_df_endtable = full_df_endtable.append(data)\n",
    "\n",
    "    if i == 9:\n",
    "        break\n",
    "\n",
    "    element = driver.find_element_by_xpath('//*[@id=\"sbprodgrid\"]/div[3]/div/nav/a[{}]'.format(i))\n",
    "    element.click()\n",
    "    \n",
    "    time.sleep(10)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "source": [
    "# Ottomans"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_ottomans = pd.DataFrame(columns=['website_link', 'image_link', 'prices', 'category'])\n",
    "\n",
    "data_dir = 'ottomans'\n",
    "\n",
    "product_dir = os.path.join('images', data_dir)\n",
    "counter = 0\n",
    "if not os.path.exists(product_dir):\n",
    "    os.makedirs(product_dir)\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--disable-blink-features=AutomationControlled') \n",
    "path = \"/usr/local/bin/chromedriver\"\n",
    "driver = webdriver.Chrome(path, options=options)\n",
    "\n",
    "url = 'https://www.allmodern.com/furniture/sb0/ottomans-poufs-c365824.html'\n",
    "driver.get(url)\n",
    "\n",
    "counter = 0 \n",
    "\n",
    "for i in range(1, 6):\n",
    "    time.sleep(2)\n",
    "    #driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "    if  6 > i >= 2:\n",
    "        i = i+1\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    img = soup.find('div', {'data-hb-id': 'pl-grid-v2'})\n",
    "\n",
    "    image_link = []\n",
    "    prices = []\n",
    "    website_link = []\n",
    "\n",
    "    for image in img.findAll('img', attrs={'srcset':True}):\n",
    "        image = image.attrs['srcset'][1+image.attrs['srcset'].find(','):image.attrs['srcset'].find('.310w')-4]\n",
    "        if ('data:image') in image:\n",
    "                pass\n",
    "        else:\n",
    "            urllib.request.urlretrieve(image, product_dir+'/'+data_dir+str(counter)+'.jpg')\n",
    "            image_link.append(image)\n",
    "            counter += 1\n",
    "    \n",
    "    for website in img.findAll('a', {'href':True}):\n",
    "        website = website['href']\n",
    "        website_link.append(website)\n",
    "\n",
    "    if i == 1:\n",
    "        for price in img.findAll('div',{'class':'ProductCard-pricing'}):\n",
    "            price = price.find('span', {'class':'ProductCard-price'}).text\n",
    "            prices.append(price)    \n",
    "    else:\n",
    "        for price in img.findAll('div',{'class':'BrowseMinimizedPriceBlock'}):\n",
    "            price = price.find('span', {'class':'BrowseMinimizedPriceBlock-price'}).text\n",
    "            prices.append(price)\n",
    "\n",
    "\n",
    "    data = pd.DataFrame(dict(zip(['website_link', 'image_link', 'prices'],[website_link, image_link, prices])))\n",
    "    data['category'] = data_dir\n",
    "    full_df_ottomans = full_df_ottomans.append(data)\n",
    "    \n",
    "    if i == 6:\n",
    "        break\n",
    "    \n",
    "    element = driver.find_element_by_xpath('//*[@id=\"sbprodgrid\"]/div[3]/div/nav/a[{}]'.format(i))\n",
    "    element.click()\n",
    "\n",
    "    time.sleep(10)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "source": [
    "# Lamps"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_lamp = pd.DataFrame(columns=['website_link', 'image_link', 'prices', 'category'])\n",
    "\n",
    "data_dir = 'lamp'\n",
    "\n",
    "product_dir = os.path.join('images', data_dir)\n",
    "counter = 0\n",
    "if not os.path.exists(product_dir):\n",
    "    os.makedirs(product_dir)\n",
    "\n",
    "path = \"/usr/local/bin/chromedriver\"\n",
    "driver = webdriver.Chrome(path)\n",
    "\n",
    "url = 'https://www.allmodern.com/lighting/sb0/table-lamps-c1872230.html'\n",
    "driver.get(url)\n",
    "\n",
    "counter = 0 \n",
    "\n",
    "for i in range(1, 5):\n",
    "    time.sleep(2)\n",
    "    #driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "    if  5 > i >= 2:\n",
    "        i = i+1\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    img = soup.find('div', {'data-hb-id': 'pl-grid-v2'})\n",
    "\n",
    "    image_link = []\n",
    "    prices = []\n",
    "    website_link = []\n",
    "\n",
    "    for image in img.findAll('img', attrs={'srcset':True}):\n",
    "        image = image.attrs['srcset'][1+image.attrs['srcset'].find(','):image.attrs['srcset'].find('.310w')-4]\n",
    "        if ('data:image') in image:\n",
    "                pass\n",
    "        else:\n",
    "            urllib.request.urlretrieve(image, product_dir+'/'+data_dir+str(counter)+'.jpg')\n",
    "            image_link.append(image)\n",
    "            counter += 1\n",
    "    \n",
    "    for website in img.findAll('a', {'href':True}):\n",
    "        website = website['href']\n",
    "        website_link.append(website)\n",
    "\n",
    "    if i == 1:\n",
    "        for price in img.findAll('div',{'class':'ProductCard-pricing'}):\n",
    "            price = price.find('span', {'class':'ProductCard-price'}).text\n",
    "            prices.append(price)    \n",
    "    else:\n",
    "        for price in img.findAll('div',{'class':'BrowseMinimizedPriceBlock'}):\n",
    "            price = price.find('span', {'class':'BrowseMinimizedPriceBlock-price'}).text\n",
    "            prices.append(price)\n",
    "\n",
    "\n",
    "    data = pd.DataFrame(dict(zip(['website_link', 'image_link', 'prices'],[website_link, image_link, prices])))\n",
    "    data['category'] = data_dir\n",
    "    full_df_lamp = full_df_lamp.append(data)\n",
    "    \n",
    "    if i == 5:\n",
    "        break\n",
    "    element = driver.find_element_by_xpath('//*[@id=\"sbprodgrid\"]/div[3]/div/nav/a[{}]'.format(i))\n",
    "    element.click()\n",
    "\n",
    "    time.sleep(10)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full_df_lamp = pd.DataFrame(columns=['website_link', 'image_link', 'prices', 'category'])\n",
    "\n",
    "data_dir = 'lamp'\n",
    "\n",
    "# product_dir = os.path.join('images', data_dir)\n",
    "# counter = 0\n",
    "# if not os.path.exists(product_dir):\n",
    "#     os.makedirs(product_dir)\n",
    "\n",
    "path = \"/usr/local/bin/chromedriver\"\n",
    "driver = webdriver.Chrome(path)\n",
    "\n",
    "url = 'https://www.allmodern.com/lighting/sb0/floor-lamps-c477075.html'\n",
    "driver.get(url)\n",
    "\n",
    "for i in range(1, 4):\n",
    "    time.sleep(2)\n",
    "    #driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "    if  4 > i >= 2:\n",
    "        i = i+1\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    img = soup.find('div', {'data-hb-id': 'pl-grid-v2'})\n",
    "\n",
    "    image_link = []\n",
    "    prices = []\n",
    "    website_link = []\n",
    "\n",
    "    for image in img.findAll('img', attrs={'srcset':True}):\n",
    "        image = image.attrs['srcset'][1+image.attrs['srcset'].find(','):image.attrs['srcset'].find('.310w')-4]\n",
    "        if ('data:image') in image:\n",
    "                pass\n",
    "        else:\n",
    "            urllib.request.urlretrieve(image, product_dir+'/'+data_dir+str(counter)+'.jpg')\n",
    "            image_link.append(image)\n",
    "            counter += 1\n",
    "    \n",
    "    for website in img.findAll('a', {'href':True}):\n",
    "        website = website['href']\n",
    "        website_link.append(website)\n",
    "\n",
    "    if i == 1:\n",
    "        for price in img.findAll('div',{'class':'ProductCard-pricing'}):\n",
    "            price = price.find('span', {'class':'ProductCard-price'}).text\n",
    "            prices.append(price)    \n",
    "    else:\n",
    "        for price in img.findAll('div',{'class':'BrowseMinimizedPriceBlock'}):\n",
    "            price = price.find('span', {'class':'BrowseMinimizedPriceBlock-price'}).text\n",
    "            prices.append(price)\n",
    "\n",
    "\n",
    "    data = pd.DataFrame(dict(zip(['website_link', 'image_link', 'prices'],[website_link, image_link, prices])))\n",
    "    data['category'] = data_dir\n",
    "    full_df_lamp = full_df_lamp.append(data)\n",
    "    \n",
    "    if i == 4:\n",
    "        break\n",
    "    element = driver.find_element_by_xpath('//*[@id=\"sbprodgrid\"]/div[3]/div/nav/a[{}]'.format(i))\n",
    "    element.click()\n",
    "\n",
    "    time.sleep(10)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "source": [
    "# Dining Tables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_diningtable = pd.DataFrame(columns=['website_link', 'image_link', 'prices', 'category'])\n",
    "\n",
    "data_dir = 'dining tables'\n",
    "\n",
    "product_dir = os.path.join('images', data_dir)\n",
    "counter = 0\n",
    "if not os.path.exists(product_dir):\n",
    "    os.makedirs(product_dir)\n",
    "\n",
    "path = \"/usr/local/bin/chromedriver\"\n",
    "driver = webdriver.Chrome(path)\n",
    "\n",
    "url = 'https://www.allmodern.com/furniture/sb0/dining-tables-c366120.html'\n",
    "driver.get(url)\n",
    "\n",
    "counter = 0 \n",
    "\n",
    "for i in range(1, 9):\n",
    "    time.sleep(2)\n",
    "    #driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "    if  5 > i >= 2:\n",
    "        i = i+1\n",
    "        \n",
    "    elif 7 > i >= 5:\n",
    "        i = 4\n",
    "    \n",
    "    elif i == 7:\n",
    "        i = 5\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    img = soup.find('div', {'data-hb-id': 'pl-grid-v2'})\n",
    "\n",
    "    image_link = []\n",
    "    prices = []\n",
    "    website_link = []\n",
    "\n",
    "    for image in img.findAll('img', attrs={'srcset':True}):\n",
    "        image = image.attrs['srcset'][1+image.attrs['srcset'].find(','):image.attrs['srcset'].find('.310w')-4]\n",
    "        if ('data:image') in image:\n",
    "                pass\n",
    "        else:\n",
    "            urllib.request.urlretrieve(image, product_dir+'/'+data_dir+str(counter)+'.jpg')\n",
    "            image_link.append(image)\n",
    "            counter += 1\n",
    "    \n",
    "    for website in img.findAll('a', {'href':True}):\n",
    "        website = website['href']\n",
    "        website_link.append(website)\n",
    "\n",
    "    if i == 1:\n",
    "        for price in img.findAll('div',{'class':'ProductCard-pricing'}):\n",
    "            price = price.find('span', {'class':'ProductCard-price'}).text\n",
    "            prices.append(price)    \n",
    "    else:\n",
    "        for price in img.findAll('div',{'class':'BrowseMinimizedPriceBlock'}):\n",
    "            price = price.find('span', {'class':'BrowseMinimizedPriceBlock-price'}).text\n",
    "            prices.append(price)\n",
    "\n",
    "\n",
    "    data = pd.DataFrame(dict(zip(['website_link', 'image_link', 'prices'],[website_link, image_link, prices])))\n",
    "    data['category'] = data_dir\n",
    "    full_df_diningtable = full_df_diningtable.append(data)\n",
    "    \n",
    "    if i == 8:\n",
    "        break\n",
    "    element = driver.find_element_by_xpath('//*[@id=\"sbprodgrid\"]/div[3]/div/nav/a[{}]'.format(i))\n",
    "    element.click()\n",
    "\n",
    "    time.sleep(10)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "347"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "len(full_df_diningtable)"
   ]
  },
  {
   "source": [
    "# Dining chair"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_diningchair = pd.DataFrame(columns=['website_link', 'image_link', 'prices', 'category'])\n",
    "\n",
    "data_dir = 'dining chair'\n",
    "\n",
    "product_dir = os.path.join('images', data_dir)\n",
    "counter = 0\n",
    "if not os.path.exists(product_dir):\n",
    "    os.makedirs(product_dir)\n",
    "\n",
    "path = \"/usr/local/bin/chromedriver\"\n",
    "driver = webdriver.Chrome(path)\n",
    "\n",
    "url = 'https://www.allmodern.com/furniture/sb0/dining-chairs-c366121.html'\n",
    "driver.get(url)\n",
    "\n",
    "counter = 0 \n",
    "\n",
    "for i in range(1, 7):\n",
    "    time.sleep(2)\n",
    "    #driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "    if  i >= 2:\n",
    "        i = i+1\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    img = soup.find('div', {'data-hb-id': 'pl-grid-v2'})\n",
    "\n",
    "    image_link = []\n",
    "    prices = []\n",
    "    website_link = []\n",
    "\n",
    "    for image in img.findAll('img', attrs={'srcset':True}):\n",
    "        image = image.attrs['srcset'][1+image.attrs['srcset'].find(','):image.attrs['srcset'].find('.310w')-4]\n",
    "        if ('data:image') in image:\n",
    "                pass\n",
    "        else:\n",
    "            urllib.request.urlretrieve(image, product_dir+'/'+data_dir+str(counter)+'.jpg')\n",
    "            image_link.append(image)\n",
    "            counter += 1\n",
    "    \n",
    "    for website in img.findAll('a', {'href':True}):\n",
    "        website = website['href']\n",
    "        website_link.append(website)\n",
    "\n",
    "\n",
    "    if i == 1:\n",
    "        for price in img.findAll('div',{'class':'ProductCard-pricing'}):\n",
    "            price = price.find('span', {'class':'ProductCard-price'}).text\n",
    "            prices.append(price)    \n",
    "    else:\n",
    "        for price in img.findAll('div',{'class':'BrowseMinimizedPriceBlock'}):\n",
    "            price = price.find('span', {'class':'BrowseMinimizedPriceBlock-price'}).text\n",
    "            prices.append(price)\n",
    "\n",
    "\n",
    "    data = pd.DataFrame(dict(zip(['website_link', 'image_link', 'prices'],[website_link, image_link, prices])))\n",
    "    data['category'] = data_dir\n",
    "    full_df_diningchair = full_df_diningchair.append(data)\n",
    "    \n",
    "    if i == 7:\n",
    "        break\n",
    "    element = driver.find_element_by_xpath('//*[@id=\"sbprodgrid\"]/div[3]/div/nav/a[{}]'.format(i))\n",
    "    element.click()\n",
    "\n",
    "    time.sleep(10)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = full_df_diningchair.append(full_df_diningtable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0        $98\n",
       "1       $130\n",
       "2        $73\n",
       "3       $320\n",
       "4       $181\n",
       "       ...  \n",
       "6     $1,820\n",
       "7       $900\n",
       "8     $1,449\n",
       "9       $980\n",
       "10    $1,000\n",
       "Name: prices, Length: 612, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "a['prices'].apply(lambda x: x.split()[1] if len(x.split()) > 1 else x.split()[0])"
   ]
  },
  {
   "source": [
    "# Rug"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_rug = pd.DataFrame(columns=['website_link', 'image_link', 'prices', 'category'])\n",
    "\n",
    "data_dir = 'rug'\n",
    "\n",
    "product_dir = os.path.join('images', data_dir)\n",
    "counter = 0\n",
    "if not os.path.exists(product_dir):\n",
    "    os.makedirs(product_dir)\n",
    "\n",
    "path = \"/usr/local/bin/chromedriver\"\n",
    "driver = webdriver.Chrome(path)\n",
    "\n",
    "url = 'https://www.allmodern.com/rugs/sb0/area-rugs-c409269.html'\n",
    "driver.get(url)\n",
    "\n",
    "counter = 0 \n",
    "\n",
    "for i in range(1, 13):\n",
    "    time.sleep(2)\n",
    "    #driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "    if  5 > i >= 2:\n",
    "        i = i+1\n",
    "        \n",
    "    elif 11 > i >= 5:\n",
    "        i = 4\n",
    "\n",
    "    elif i == 11:\n",
    "        i = 5\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    img = soup.find('div', {'data-hb-id': 'pl-grid-v2'})\n",
    "\n",
    "    image_link = []\n",
    "    prices = []\n",
    "    website_link = []\n",
    "\n",
    "    for image in img.findAll('img', attrs={'srcset':True}):\n",
    "        image = image.attrs['srcset'][1+image.attrs['srcset'].find(','):image.attrs['srcset'].find('.310w')-4]\n",
    "        if ('data:image') in image:\n",
    "                pass\n",
    "        else:\n",
    "            urllib.request.urlretrieve(image, product_dir+'/'+data_dir+str(counter)+'.jpg')\n",
    "            image_link.append(image)\n",
    "            counter += 1\n",
    "    \n",
    "    for website in img.findAll('a', {'href':True}):\n",
    "        website = website['href']\n",
    "        website_link.append(website)\n",
    "\n",
    "    if i == 1:\n",
    "        for price in img.findAll('div',{'class':'ProductCard-pricing'}):\n",
    "            price = price.find('span', {'class':'ProductCard-price'}).text\n",
    "            prices.append(price)    \n",
    "    else:\n",
    "        for price in img.findAll('div',{'class':'BrowseMinimizedPriceBlock'}):\n",
    "            price = price.find('span', {'class':'BrowseMinimizedPriceBlock-price'}).text\n",
    "            prices.append(price)\n",
    "\n",
    "\n",
    "    data = pd.DataFrame(dict(zip(['website_link', 'image_link', 'prices'],[website_link, image_link, prices])))\n",
    "    data['category'] = data_dir\n",
    "    full_df_rug = full_df_rug.append(data)\n",
    "\n",
    "    if i == 12:\n",
    "        break\n",
    "\n",
    "    element = driver.find_element_by_xpath('//*[@id=\"sbprodgrid\"]/div[3]/div/nav/a[{}]'.format(i))\n",
    "    element.click()\n",
    "    \n",
    "    time.sleep(10)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "source": [
    "# Wall Art\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_wallart = pd.DataFrame(columns=['website_link', 'image_link', 'prices', 'category'])\n",
    "\n",
    "data_dir = 'wall art'\n",
    "\n",
    "product_dir = os.path.join('images', data_dir)\n",
    "counter = 0\n",
    "if not os.path.exists(product_dir):\n",
    "    os.makedirs(product_dir)\n",
    "\n",
    "path = \"/usr/local/bin/chromedriver\"\n",
    "driver = webdriver.Chrome(path)\n",
    "\n",
    "url = 'https://www.allmodern.com/decor-pillows/sb0/wall-art-c446716.html?prefetch=true'\n",
    "driver.get(url)\n",
    "\n",
    "counter = 0 \n",
    "\n",
    "for i in range(1, 16):\n",
    "    time.sleep(2)\n",
    "    #driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "    if  5 > i >= 2:\n",
    "        i = i+1\n",
    "        \n",
    "    elif 14 > i >= 5:\n",
    "        i = 4\n",
    "\n",
    "    elif i == 14:\n",
    "        i = 5\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    img = soup.find('div', {'data-hb-id': 'pl-grid-v2'})\n",
    "\n",
    "    image_link = []\n",
    "    prices = []\n",
    "    website_link = []\n",
    "\n",
    "    for image in img.findAll('img', attrs={'srcset':True}):\n",
    "        image = image.attrs['srcset'][1+image.attrs['srcset'].find(','):image.attrs['srcset'].find('.310w')-4]\n",
    "        if ('data:image') in image:\n",
    "                pass\n",
    "        else:\n",
    "            urllib.request.urlretrieve(image, product_dir+'/'+data_dir+str(counter)+'.jpg')\n",
    "            image_link.append(image)\n",
    "            counter += 1\n",
    "    \n",
    "    for website in img.findAll('a', {'href':True}):\n",
    "        website = website['href']\n",
    "        website_link.append(website)\n",
    "\n",
    "    # if i == 1:\n",
    "    for price in img.findAll('div',{'class':'ProductCard-pricing'}):\n",
    "        price = price.find('span', {'class':'ProductCard-price'}).text\n",
    "        prices.append(price)    \n",
    "    # else:\n",
    "    #     for price in img.findAll('div',{'class':'BrowseMinimizedPriceBlock'}):\n",
    "    #         price = price.find('span', {'class':'BrowseMinimizedPriceBlock-price'}).text\n",
    "    #         prices.append(price)\n",
    "\n",
    "\n",
    "    data = pd.DataFrame(dict(zip(['website_link', 'image_link', 'prices'],[website_link, image_link, prices])))\n",
    "    data['category'] = data_dir\n",
    "    full_df_wallart = full_df_wallart.append(data)\n",
    "\n",
    "    if i == 15:\n",
    "        break\n",
    "\n",
    "    element = driver.find_element_by_xpath('//*[@id=\"sbprodgrid\"]/div[3]/div/nav/a[{}]'.format(i))\n",
    "    element.click()\n",
    "    \n",
    "    time.sleep(10)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = [full_df_rug, full_df_lamp, full_df_diningchair, full_df_diningtable, full_df_sofa, full_df_chair, full_df_coffeetable, full_df_consoletable, full_df_endtable, full_df_ottomans, full_df_tvstand]\n",
    "\n",
    "full_df = pd.DataFrame(columns=['website_link', 'image_link', 'prices', 'category'])\n",
    "\n",
    "for i in list:\n",
    "    full_df = full_df.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pickle.load(open('full_df.p', 'rb'))\n",
    "\n",
    "grouped = df.groupby('category', as_index=False)\n",
    "grouped_index = grouped.apply(lambda x: x.reset_index(drop = True)).reset_index()\n",
    "result = grouped_index.drop('level_0',axis = 1).set_index('level_1').reset_index()\n",
    "result['id'] = result.apply(lambda x: x['category']+str(x['level_1']), axis=1)\n",
    "\n",
    "pickle.dump(result, open('result.p', 'wb'))"
   ]
  }
 ]
}